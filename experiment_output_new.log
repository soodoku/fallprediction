
====================================================================================================
                          FALL PREDICTION - COMPREHENSIVE MODEL COMPARISON                          
====================================================================================================

Experiment started: 2025-11-10 02:06:12
Output directories created/verified.

================================================================================
Loading and Preparing Data
================================================================================
Loaded data: 171 samples, 63 columns

Warning: Found 1 NaN values across 1 columns
NaN values filled with column medians
Features: 61 columns
Target distribution: Fallers=34, Non-Fallers=137

Train set: 128 samples (Fallers=25)
Test set: 43 samples (Fallers=9)
Features scaled using StandardScaler

Class distribution: {'Faller': np.int64(34), 'Non-Faller': np.int64(137), 'Faller_pct': np.float64(19.883040935672515), 'Non-Faller_pct': np.float64(80.11695906432749), 'Total': 171}

================================================================================
Training Random Forest Models
================================================================================

1. Training Random Forest (Default)...
   OOB Score: 0.8203

2. Training Random Forest (500 trees)...
   OOB Score: 0.8047

3. Training Random Forest (RandomizedSearchCV)...
   Best params: {'n_estimators': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None, 'max_depth': 20, 'class_weight': None}
   Best CV score: 0.6842

================================================================================
Training Gradient Boosting Models
================================================================================

1. Training Gradient Boosting (Default)...

2. Training Gradient Boosting (RandomizedSearchCV)...
   Best params: {'subsample': 1.0, 'n_estimators': 50, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_depth': 3, 'learning_rate': 0.05}
   Best CV score: 0.6946

================================================================================
Training XGBoost Models
================================================================================

1. Training XGBoost (Default)...

2. Training XGBoost (RandomizedSearchCV)...
   Best params: {'subsample': 0.8, 'scale_pos_weight': 1, 'n_estimators': 50, 'min_child_weight': 1, 'max_depth': 7, 'learning_rate': 0.1, 'gamma': 0, 'colsample_bytree': 0.8}
   Best CV score: 0.6456

================================================================================
Training Support Vector Machine Models
================================================================================

1. Training SVM (RBF kernel, GridSearchCV)...
   Best params: {'C': 1, 'class_weight': 'balanced', 'gamma': 0.001}
   Best CV score: 0.6730

2. Training SVM (Linear kernel)...
   Best params: {'C': 0.1, 'class_weight': None}
   Best CV score: 0.6269

================================================================================
Training Neural Network Models
================================================================================

1. Training Neural Network (Simple)...

2. Training Neural Network (GridSearchCV)...
   Best params: {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'constant'}
   Best CV score: 0.7115

================================================================================
Training Logistic Regression Models
================================================================================

1. Training Logistic Regression (L2)...

2. Training Logistic Regression (GridSearchCV)...
   Best params: {'C': 0.01, 'class_weight': None, 'penalty': 'l2'}
   Best CV score: 0.6909

================================================================================
Evaluating Models with Bootstrap Standard Errors
================================================================================

Evaluating RF_Default...

Evaluating RF_500trees...

Evaluating RF_Tuned...

Evaluating GradientBoosting_Default...

Evaluating GradientBoosting_Tuned...

Evaluating XGBoost_Default...

Evaluating XGBoost_Tuned...

Evaluating SVM_RBF...

Evaluating SVM_Linear...

Evaluating NeuralNet_Simple...

Evaluating NeuralNet_Tuned...

Evaluating LogisticRegression_L2...

Evaluating LogisticRegression_Tuned...

====================================================================================================
                               COMPREHENSIVE MODEL COMPARISON RESULTS                               
====================================================================================================
                   Model  OOB_Score  TP  TN  FP  FN  AUC_ROC  AUC_ROC_SE  AUC_PR  AUC_PR_SE  ACCURACY  ACCURACY_SE  SENSITIVITY  SENSITIVITY_SE  SPECIFICITY  SPECIFICITY_SE  PRECISION  PRECISION_SE     F1  F1_SE
              RF_Default     0.8203   0  31   3   9   0.6031      0.0974  0.3197     0.1059    0.7245       0.0694       0.0000          0.0000       0.9132          0.0477     0.0000        0.0000 0.0000 0.0000
             RF_500trees     0.8047   0  30   4   9   0.6412      0.0942  0.3206     0.1024    0.7004       0.0708       0.0000          0.0000       0.8829          0.0547     0.0000        0.0000 0.0000 0.0000
                RF_Tuned     0.7734   2  29   5   7   0.5989      0.1041  0.3831     0.1337    0.7219       0.0704       0.2208          0.1453       0.8526          0.0592     0.2784        0.1762 0.2358 0.1433
GradientBoosting_Default        NaN   3  26   8   6   0.5743      0.1160  0.3734     0.1357    0.6751       0.0740       0.3316          0.1638       0.7643          0.0739     0.2688        0.1366 0.2868 0.1344
  GradientBoosting_Tuned        NaN   3  31   3   6   0.5639      0.1235  0.4228     0.1454    0.7913       0.0630       0.3316          0.1638       0.9110          0.0479     0.4919        0.2252 0.3804 0.1675
         XGBoost_Default        NaN   0  31   3   9   0.5888      0.0951  0.2794     0.0876    0.7242       0.0692       0.0000          0.0000       0.9128          0.0475     0.0000        0.0000 0.0000 0.0000
           XGBoost_Tuned        NaN   0  32   2   9   0.5443      0.0921  0.2624     0.0867    0.7474       0.0665       0.0000          0.0000       0.9422          0.0392     0.0000        0.0000 0.0000 0.0000
                 SVM_RBF        NaN   1  28   6   8   0.4921      0.1180  0.2590     0.0911    0.6754       0.0731       0.1108          0.1111       0.8222          0.0656     0.1427        0.1454 0.1184 0.1135
              SVM_Linear        NaN   0  30   4   9   0.5174      0.1044  0.2521     0.0828    0.7016       0.0704       0.0000          0.0000       0.8844          0.0539     0.0000        0.0000 0.0000 0.0000
        NeuralNet_Simple        NaN   0  26   8   9   0.3884      0.1095  0.2094     0.0707    0.6047       0.0755       0.0000          0.0000       0.7622          0.0721     0.0000        0.0000 0.0000 0.0000
         NeuralNet_Tuned        NaN   3  23  11   6   0.5373      0.1160  0.3002     0.1130    0.6080       0.0763       0.3384          0.1671       0.6781          0.0820     0.2151        0.1135 0.2545 0.1213
   LogisticRegression_L2        NaN   0  27   7   9   0.4272      0.0929  0.2116     0.0659    0.6292       0.0735       0.0000          0.0000       0.7932          0.0692     0.0000        0.0000 0.0000 0.0000
LogisticRegression_Tuned        NaN   0  34   0   9   0.4537      0.1152  0.2402     0.0834    0.7932       0.0623       0.0000          0.0000       1.0000          0.0000     0.0000        0.0000 0.0000 0.0000
====================================================================================================

Best AUC-ROC: RF_500trees (0.6412 ± 0.0942)

Best AUC-PR: GradientBoosting_Tuned (0.4228 ± 0.1454)

Best Accuracy: LogisticRegression_Tuned (0.7932 ± 0.0623)

Best Sensitivity: NeuralNet_Tuned (0.3384 ± 0.1671)



Results saved to: outputs/results/model_comparison_results.csv
Threshold comparison results saved to: outputs/results/threshold_comparison.csv

====================================================================================================
                   THRESHOLD COMPARISON: DEFAULT (0.5) vs OPTIMAL (F1-Maximizing)                   
====================================================================================================
                   Model     Threshold  Threshold_Value  SENSITIVITY  SENSITIVITY_SE  SPECIFICITY  SPECIFICITY_SE  PRECISION  PRECISION_SE     F1  F1_SE  ACCURACY  ACCURACY_SE  TP  TN  FP  FN
              RF_Default Default (0.5)           0.5000       0.0000          0.0000       0.9132          0.0477     0.0000        0.0000 0.0000 0.0000    0.7245       0.0694   0  31   3   9
              RF_Default  Optimal (F1)           0.1900       0.7760          0.1401       0.5018          0.0924     0.2894        0.0933 0.4139 0.1083    0.5584       0.0802   7  17  17   2
             RF_500trees Default (0.5)           0.5000       0.0000          0.0000       0.8829          0.0547     0.0000        0.0000 0.0000 0.0000    0.7004       0.0708   0  30   4   9
             RF_500trees  Optimal (F1)           0.2030       0.7760          0.1401       0.5605          0.0908     0.3160        0.1004 0.4407 0.1122    0.6049       0.0786   7  19  15   2
                RF_Tuned Default (0.5)           0.5000       0.2208          0.1453       0.8526          0.0592     0.2784        0.1762 0.2358 0.1433    0.7219       0.0704   2  29   5   7
                RF_Tuned  Optimal (F1)           0.0990       1.0000          0.0000       0.3267          0.0827     0.2791        0.0804 0.4303 0.0987    0.4660       0.0774   9  11  23   0
GradientBoosting_Default Default (0.5)           0.5000       0.3316          0.1638       0.7643          0.0739     0.2688        0.1366 0.2868 0.1344    0.6751       0.0740   3  26   8   6
GradientBoosting_Default  Optimal (F1)           0.0122       1.0000          0.0000       0.1744          0.0656     0.2399        0.0706 0.3818 0.0921    0.3452       0.0725   9   6  28   0
  GradientBoosting_Tuned Default (0.5)           0.5000       0.3316          0.1638       0.9110          0.0479     0.4919        0.2252 0.3804 0.1675    0.7913       0.0630   3  31   3   6
  GradientBoosting_Tuned  Optimal (F1)           0.5387       0.3316          0.1638       0.9404          0.0393     0.5857        0.2451 0.4069 0.1743    0.8146       0.0596   3  32   2   6
         XGBoost_Default Default (0.5)           0.5000       0.0000          0.0000       0.9128          0.0475     0.0000        0.0000 0.0000 0.0000    0.7242       0.0692   0  31   3   9
         XGBoost_Default  Optimal (F1)           0.0499       0.8886          0.1098       0.3858          0.0857     0.2735        0.0829 0.4117 0.1008    0.4896       0.0767   8  13  21   1
           XGBoost_Tuned Default (0.5)           0.5000       0.0000          0.0000       0.9422          0.0392     0.0000        0.0000 0.0000 0.0000    0.7474       0.0665   0  32   2   9
           XGBoost_Tuned  Optimal (F1)           0.0841       0.7757          0.1480       0.4663          0.0857     0.2744        0.0901 0.3981 0.1073    0.5301       0.0761   7  16  18   2
                 SVM_RBF Default (0.5)           0.5000       0.1108          0.1111       0.8222          0.0656     0.1427        0.1454 0.1184 0.1135    0.6754       0.0731   1  28   6   8
                 SVM_RBF  Optimal (F1)           0.1948       0.8871          0.1100       0.2004          0.0680     0.2243        0.0705 0.3529 0.0929    0.3427       0.0705   8   7  27   1
              SVM_Linear Default (0.5)           0.5000       0.0000          0.0000       0.8844          0.0539     0.0000        0.0000 0.0000 0.0000    0.7016       0.0704   0  30   4   9
              SVM_Linear  Optimal (F1)           0.1228       0.8866          0.1122       0.2951          0.0797     0.2468        0.0764 0.3804 0.0974    0.4177       0.0756   8  10  24   1
        NeuralNet_Simple Default (0.5)           0.5000       0.0000          0.0000       0.7622          0.0721     0.0000        0.0000 0.0000 0.0000    0.6047       0.0755   0  26   8   9
        NeuralNet_Simple  Optimal (F1)           0.0953       1.0000          0.0000       0.0897          0.0486     0.2225        0.0661 0.3593 0.0885    0.2780       0.0673   9   3  31   0
         NeuralNet_Tuned Default (0.5)           0.5000       0.3384          0.1671       0.6781          0.0820     0.2151        0.1135 0.2545 0.1213    0.6080       0.0763   3  23  11   6
         NeuralNet_Tuned  Optimal (F1)           0.2408       1.0000          0.0000       0.1447          0.0585     0.2335        0.0690 0.3735 0.0907    0.3216       0.0699   9   5  29   0
   LogisticRegression_L2 Default (0.5)           0.5000       0.0000          0.0000       0.7932          0.0692     0.0000        0.0000 0.0000 0.0000    0.6292       0.0735   0  27   7   9
   LogisticRegression_L2  Optimal (F1)           0.0146       1.0000          0.0000       0.2064          0.0691     0.2470        0.0715 0.3909 0.0923    0.3708       0.0712   9   7  27   0
LogisticRegression_Tuned Default (0.5)           0.5000       0.0000          0.0000       1.0000          0.0000     0.0000        0.0000 0.0000 0.0000    0.7932       0.0623   0  34   0   9
LogisticRegression_Tuned  Optimal (F1)           0.0998       1.0000          0.0000       0.1147          0.0545     0.2273        0.0671 0.3656 0.0892    0.2979       0.0683   9   4  30   0
====================================================================================================

Generating visualizations...
ROC curves saved to: outputs/figures/roc_curves.png
Precision-Recall curves saved to: outputs/figures/pr_curves.png
Metrics comparison saved to: outputs/figures/metrics_comparison.png
Confusion matrices saved to: outputs/figures/confusion_matrices.png
Comprehensive comparison saved to: outputs/figures/comprehensive_comparison.png
All visualizations generated successfully!
Detailed bootstrap results saved to: outputs/results/detailed_bootstrap_results.csv

====================================================================================================
Experiment completed: 2025-11-10 02:08:44
====================================================================================================
